---
description: 基于GPT/AIGC/LLM的各类安全工具
---

# Security Tools

目前，GPT 系列模型在网络安全领域的应用还相对较少，但随着大型语言模型的发展，越来越多的开源工具和项目开始尝试将 GPT 应用于网络安全。以下是一些使用 GPT 进行网络安全研究和实践的开源工具：

1. **OpenAI Codex：**虽然 OpenAI Codex 本身并非专门针对网络安全设计的工具，但它基于 GPT-3.5-turbo 模型，可用于编写、审查和分析代码，包括网络安全相关的代码。您可以利用 Codex 的 API 来构建与网络安全相关的自动化工具，例如自动生成漏洞扫描脚本或辅助渗透测试。
2. **GPT-3 Sandbox：**GPT-3 Sandbox 是一个可用于快速实验和测试 GPT-3 的在线平台。虽然它同样不是专门为网络安全设计的，但您可以利用该平台为 GPT-3 提供网络安全相关的预设指令（Prompts），从而探索 GPT-3 在网络安全领域的潜在应用。
3.  **BurpGPT：**\
    [https://github.com/aress31/burpgpt](https://github.com/aress31/burpgpt)\
    `burpgpt` 是一个开源项目，结合了 Burp Suite 和 OpenAI 的 GPT-3 模型。Burp Suite 是一款广受欢迎的网络安全工具，主要用于 Web 应用程序的渗透测试。该项目旨在利用 GPT-3 的强大生成能力，为网络安全专业人员提供更智能的安全工具。\


    `burpgpt` 的主要功能如下：

    1. 自动生成有效的有效负载：根据给定的上下文和目标，利用 GPT-3 自动生成可能导致安全漏洞的有效负载。
    2. 检测潜在的安全漏洞：使用 GPT-3 分析请求和响应数据，自动识别潜在的安全风险。
    3. 自动化报告生成：借助 GPT-3，将渗透测试结果整理成易于理解的报告，提高报告编写效率。
    4. 模糊测试支持：利用 GPT-3 自动生成随机有效负载，用于模糊测试以发现潜在漏洞。



目前，将 GPT 应用于网络安全的开源工具和项目尚处于起步阶段。在未来，随着大型语言模型的进一步发展，我们可以期待会有更多的项目和工具涌现，为网络安全领域带来更多的创新和价值。

